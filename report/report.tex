\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

\usepackage[margin=1in]{geometry}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size \usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}

\title{Video Query Processing with Text}
\author{Sinclair Hudson}

\begin{document}
\maketitle

\begin{abstract}
      While LLMs are now frequently extended to process visual information in the form of images, they are not yet commonly used to process video.
      This work explores a general pipeline that leverages large language models (LLMs) to convert video into textual descriptions, and then further retrieve clips relevant to a query using those textual descriptions.
      The pipeline is called the VideoDescriptor pipeline, and is evaluated on text-to-video retrieval as well as video summarization.
      While not as accurate as other methods, the VideoDescriptor pipeline is able to achieve reasonable results on both tasks, and is completely zero-shot.
      Code for all experiments is available at \url{https://github.com/SinclairHudson/video-understanding}.
\end{abstract}

\input{introduction}

\input{related_work}

\input{method}

\input{results}

\input{discussion}

\input{future_work}

\section{Conclusion}

While supervised methods still perform much better than the VideoDescriptor pipeline on text to video retrieval, the VideoDescriptor shows potential for zero-shot retrieval.
Additionally, it can be used for video summarization, and generates compelling videos for queries relating to specific objects in the video.
Hopefully, the performance of the VideoDescriptor pipeline improves as multimodal language models improve.

\bibliographystyle{alpha}
\bibliography{biblio}

\end{document}
